{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "00583501-2ca8-4b71-9053-2d4da9e742f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install pandarallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "b0fea0f2-226f-4c76-913f-9c6064972489",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Available CPUs: 16\n"
     ]
    }
   ],
   "source": [
    "from pandarallel import pandarallel\n",
    "import multiprocessing\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "print(f'Available CPUs: {num_processors}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "81205e5d-3c61-4112-ae9a-135a0429040b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO: Pandarallel will run on 15 workers.\n",
      "INFO: Pandarallel will use standard multiprocessing data transfer (pipe) to transfer data between the main process and workers.\n"
     ]
    }
   ],
   "source": [
    "pandarallel.initialize(nb_workers=num_processors-1, use_memory_fs=False, progress_bar = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "834da5fe-464a-424e-b352-f82e3ad402a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "98400f78-d7aa-47bf-8f73-e54ec00c4138",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "# warnings.simplefilter('once')\n",
    "warnings.simplefilter('ignore')\n",
    "# warnings.filterwarnings(\"ignore\", category=FutureWarning)\n",
    "# warnings.filterwarnings(\"ignore\", category=DeprecationWarning)\n",
    "# warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c0ad1c0-271c-45ec-bda8-367aa082116e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29.6 s, sys: 13 s, total: 42.5 s\n",
      "Wall time: 32.4 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df = pd.read_parquet(\"filtered_data.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "48fc0aec-c5a0-48eb-a98e-a9a817098217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>main_text</th>\n",
       "      <th>relevant</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://en.people.cn/n3/2021/0318/c90000-983012...</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>Artificial intelligence improves parking effic...</td>\n",
       "      <td>\\n\\nArtificial intelligence improves parking e...</td>\n",
       "      <td>Photo taken on July 1, 2019, shows a sign for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Photo, taken, on, July, 1, ,, 2019, ,, shows,...</td>\n",
       "      <td>[Photo, taken, July, show, sign, electronic, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://newsparliament.com/2020/02/27/children-...</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>Children With Autism Saw Their Learning and So...</td>\n",
       "      <td>\\nChildren With Autism Saw Their Learning and ...</td>\n",
       "      <td>Children With Autism Saw Their Learning and So...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Children, With, Autism, Saw, Their, Learning,...</td>\n",
       "      <td>[Children, With, Autism, Saw, Their, Learning,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.dataweek.co.za/12835r</td>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>Forget ML, AI and Industry 4.0 – obsolescence ...</td>\n",
       "      <td>\\n\\nForget ML, AI and Industry 4.0 – obsolesce...</td>\n",
       "      <td>Forget ML, AI and Industry 4.0 – obsolescence ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Forget, ML, ,, AI, and, Industry, 4.0, –, obs...</td>\n",
       "      <td>[Forget, ML, AI, Industry, obsolescence, focus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.homeoffice.consumerelectronicsnet.c...</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>Strategy Analytics: 71% of Smartphones Sold Gl...</td>\n",
       "      <td>\\n\\nStrategy Analytics: 71% of Smartphones Sol...</td>\n",
       "      <td>Strategy Analytics: 71% of Smartphones Sold Gl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Strategy, Analytics, :, 71, %, of, Smartphone...</td>\n",
       "      <td>[Strategy, Analytics, Smartphones, Sold, Globa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.itbusinessnet.com/2020/10/olympus-t...</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>Olympus to Support Endoscopic AI Diagnosis Edu...</td>\n",
       "      <td>\\n\\nOlympus to Support Endoscopic AI Diagnosis...</td>\n",
       "      <td>Olympus to Support Endoscopic AI Diagnosis Edu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Olympus, to, Support, Endoscopic, AI, Diagnos...</td>\n",
       "      <td>[Olympus, Support, Endoscopic, AI, Diagnosis, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url        date  \\\n",
       "0  http://en.people.cn/n3/2021/0318/c90000-983012...  2021-03-18   \n",
       "1  http://newsparliament.com/2020/02/27/children-...  2020-02-27   \n",
       "2                   http://www.dataweek.co.za/12835r  2021-03-26   \n",
       "3  http://www.homeoffice.consumerelectronicsnet.c...  2021-03-10   \n",
       "4  http://www.itbusinessnet.com/2020/10/olympus-t...  2020-10-20   \n",
       "\n",
       "                                               title  \\\n",
       "0  Artificial intelligence improves parking effic...   \n",
       "1  Children With Autism Saw Their Learning and So...   \n",
       "2  Forget ML, AI and Industry 4.0 – obsolescence ...   \n",
       "3  Strategy Analytics: 71% of Smartphones Sold Gl...   \n",
       "4  Olympus to Support Endoscopic AI Diagnosis Edu...   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\n\\nArtificial intelligence improves parking e...   \n",
       "1  \\nChildren With Autism Saw Their Learning and ...   \n",
       "2  \\n\\nForget ML, AI and Industry 4.0 – obsolesce...   \n",
       "3  \\n\\nStrategy Analytics: 71% of Smartphones Sol...   \n",
       "4  \\n\\nOlympus to Support Endoscopic AI Diagnosis...   \n",
       "\n",
       "                                           main_text  relevant  \\\n",
       "0  Photo taken on July 1, 2019, shows a sign for ...         1   \n",
       "1  Children With Autism Saw Their Learning and So...         1   \n",
       "2  Forget ML, AI and Industry 4.0 – obsolescence ...         1   \n",
       "3  Strategy Analytics: 71% of Smartphones Sold Gl...         1   \n",
       "4  Olympus to Support Endoscopic AI Diagnosis Edu...         1   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [Photo, taken, on, July, 1, ,, 2019, ,, shows,...   \n",
       "1  [Children, With, Autism, Saw, Their, Learning,...   \n",
       "2  [Forget, ML, ,, AI, and, Industry, 4.0, –, obs...   \n",
       "3  [Strategy, Analytics, :, 71, %, of, Smartphone...   \n",
       "4  [Olympus, to, Support, Endoscopic, AI, Diagnos...   \n",
       "\n",
       "                                      cleaned_tokens  \n",
       "0  [Photo, taken, July, show, sign, electronic, t...  \n",
       "1  [Children, With, Autism, Saw, Their, Learning,...  \n",
       "2  [Forget, ML, AI, Industry, obsolescence, focus...  \n",
       "3  [Strategy, Analytics, Smartphones, Sold, Globa...  \n",
       "4  [Olympus, Support, Endoscopic, AI, Diagnosis, ...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "18a4c469-f56c-4d05-b28e-45ba167d17c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(127739, 8)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11e74d4-a29a-44eb-bc28-e323e69b8eab",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## LDA with gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5789cbb0-94e5-48f1-8c92-ea5a1b57a1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob\n",
    "!pip install nltk\n",
    "!pip install gensim\n",
    "!pip install pyLDAvis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3263bdb-2738-43a1-9936-3d9f925be53e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import math\n",
    "import re\n",
    "from textblob import TextBlob\n",
    "\n",
    "\n",
    "import nltk as nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "import string\n",
    "\n",
    "\n",
    "import gensim\n",
    "from gensim import corpora, models\n",
    "from gensim.models.ldamulticore import LdaMulticore\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.models import CoherenceModel\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "# import pyLDAvis.gensim\n",
    "import pyLDAvis\n",
    "import pyLDAvis.gensim_models as gensimvis\n",
    "pyLDAvis.enable_notebook()\n",
    "\n",
    "import multiprocessing\n",
    "\n",
    "num_processors = multiprocessing.cpu_count()\n",
    "num_processors\n",
    "workers=num_processors-1\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24afede1-af98-41fc-8c15-93beaf8cc374",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define helper function\n",
    "def dict_doc_term(text_df):\n",
    "    \n",
    "    doc_clean = text_df.to_list()\n",
    "    \n",
    "    # Creating the term dictionary of our courpus, where every unique term is assigned an index. \n",
    "    dictionary = corpora.Dictionary(doc_clean)\n",
    "\n",
    "    # Converting list of documents (corpus) into Document Term Matrix using dictionary prepared above.\n",
    "    doc_term_matrix = [dictionary.doc2bow(doc) for doc in doc_clean]\n",
    "    \n",
    "    return doc_clean, dictionary, doc_term_matrix\n",
    "\n",
    "\n",
    "def n_topic(doc_clean, dictionary, doc_term_matrix, topic_ls):\n",
    "    \n",
    "    coherence_score = []\n",
    "    \n",
    "    for n in tqdm(topic_ls):\n",
    "\n",
    "        lda_model = LdaMulticore(corpus = doc_term_matrix,\n",
    "                   id2word = dictionary,\n",
    "                   num_topics = n,\n",
    "                   random_state = 100,\n",
    "                   passes = 10,\n",
    "                   alpha = 'symmetric',\n",
    "                   eta = 'auto',\n",
    "                   workers = workers)\n",
    "        \n",
    "        coherence_model_lda = CoherenceModel(model = lda_model, texts = doc_clean, dictionary = dictionary, coherence = 'c_v')\n",
    "        coherence_lda = coherence_model_lda.get_coherence()\n",
    "        coherence_score.append(coherence_lda)\n",
    "        \n",
    "        print(f'\\nWith {n} topics:')\n",
    "        print(*lda_model.print_topics(num_topics = n, num_words = 10), sep='\\n')\n",
    "        \n",
    "    return pd.DataFrame({\"n\": topic_ls, \"coherence_score\": coherence_score})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d038b102-8894-4992-83e8-a08420141b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2min 21s, sys: 1.96 s, total: 2min 22s\n",
      "Wall time: 2min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "df_cleaned, df_dict, df_matrix = dict_doc_term(df['cleaned_tokens'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d801ba2d-81ff-4c79-bf7c-0263c97e06c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [1:03:06<00:00, 3786.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "With 16 topics:\n",
      "(0, '0.023*\"Paid\" + 0.021*\"Program\" + 0.019*\"Best\" + 0.017*\"BrandVoice\" + 0.014*\"AI\" + 0.012*\"Forbes\" + 0.010*\"Richest\" + 0.008*\"The\" + 0.007*\"Insurance\" + 0.006*\"Credit\"')\n",
      "(1, '0.038*\"market\" + 0.029*\"Market\" + 0.021*\"Artificial\" + 0.021*\"Intelligence\" + 0.018*\"report\" + 0.015*\"The\" + 0.014*\"AI\" + 0.010*\"Global\" + 0.009*\"growth\" + 0.008*\"analysis\"')\n",
      "(2, '0.020*\"Finance\" + 0.014*\"Screener\" + 0.013*\"Yahoo\" + 0.010*\"News\" + 0.009*\"AI\" + 0.009*\"Fund\" + 0.008*\"ETF\" + 0.008*\"Stocks\" + 0.007*\"Markets\" + 0.007*\"stock\"')\n",
      "(3, '0.013*\"patient\" + 0.010*\"The\" + 0.010*\"AI\" + 0.008*\"healthcare\" + 0.008*\"health\" + 0.006*\"medical\" + 0.005*\"data\" + 0.005*\"disease\" + 0.005*\"study\" + 0.005*\"care\"')\n",
      "(4, '0.012*\"AI\" + 0.012*\"The\" + 0.009*\"said\" + 0.006*\"country\" + 0.006*\"people\" + 0.006*\"We\" + 0.005*\"government\" + 0.005*\"China\" + 0.005*\"technology\" + 0.004*\"also\"')\n",
      "(5, '0.012*\"AI\" + 0.011*\"The\" + 0.010*\"technology\" + 0.007*\"system\" + 0.007*\"intelligence\" + 0.006*\"artificial\" + 0.005*\"statement\" + 0.004*\"company\" + 0.004*\"information\" + 0.004*\"Company\"')\n",
      "(6, '0.032*\"AI\" + 0.010*\"car\" + 0.008*\"Product\" + 0.007*\"product\" + 0.007*\"The\" + 0.005*\"might\" + 0.005*\"human\" + 0.005*\"system\" + 0.004*\"driving\" + 0.004*\"would\"')\n",
      "(7, '0.021*\"AI\" + 0.009*\"The\" + 0.008*\"chip\" + 0.007*\"NVIDIA\" + 0.007*\"device\" + 0.006*\"edge\" + 0.006*\"application\" + 0.006*\"new\" + 0.005*\"computing\" + 0.005*\"performance\"')\n",
      "(8, '0.008*\"To\" + 0.007*\"AI\" + 0.006*\"The\" + 0.005*\"News\" + 0.005*\"India\" + 0.004*\"Philips\" + 0.004*\"New\" + 0.004*\"In\" + 0.004*\"de\" + 0.004*\"For\"')\n",
      "(9, '0.010*\"insurance\" + 0.010*\"ChatGPT\" + 0.010*\"student\" + 0.008*\"The\" + 0.007*\"said\" + 0.007*\"quote\" + 0.007*\"AI\" + 0.006*\"school\" + 0.004*\"online\" + 0.004*\"car\"')\n",
      "(10, '0.010*\"The\" + 0.010*\"say\" + 0.010*\"AI\" + 0.006*\"human\" + 0.005*\"like\" + 0.005*\"voice\" + 0.005*\"music\" + 0.005*\"It\" + 0.004*\"could\" + 0.004*\"said\"')\n",
      "(11, '0.025*\"AI\" + 0.012*\"company\" + 0.010*\"customer\" + 0.008*\"business\" + 0.008*\"The\" + 0.007*\"technology\" + 0.007*\"data\" + 0.007*\"platform\" + 0.006*\"solution\" + 0.006*\"service\"')\n",
      "(12, '0.014*\"News\" + 0.014*\"India\" + 0.009*\"AI\" + 0.007*\"The\" + 0.005*\"Crypto\" + 0.004*\"Digital\" + 0.004*\"Under\" + 0.004*\"cookie\" + 0.004*\"Indian\" + 0.003*\"cooky\"')\n",
      "(13, '0.022*\"data\" + 0.017*\"AI\" + 0.011*\"learning\" + 0.008*\"model\" + 0.008*\"machine\" + 0.007*\"The\" + 0.006*\"Data\" + 0.005*\"science\" + 0.005*\"use\" + 0.005*\"system\"')\n",
      "(14, '0.017*\"AI\" + 0.010*\"The\" + 0.007*\"new\" + 0.007*\"ChatGPT\" + 0.006*\"Google\" + 0.006*\"like\" + 0.005*\"It\" + 0.005*\"said\" + 0.005*\"company\" + 0.004*\"also\"')\n",
      "(15, '0.020*\"AI\" + 0.019*\"said\" + 0.017*\"OpenAI\" + 0.017*\"The\" + 0.014*\"ChatGPT\" + 0.014*\"Microsoft\" + 0.014*\"company\" + 0.008*\"technology\" + 0.008*\"data\" + 0.007*\"intelligence\"')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "#%%time\n",
    "df_score = n_topic(df_cleaned, df_dict, df_matrix, [16])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bac509-174a-4ef4-8820-163d12f3aa5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n</th>\n",
       "      <th>coherence_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>16</td>\n",
       "      <td>0.463993</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    n  coherence_score\n",
       "0  16         0.463993"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df80b0c8-1e89-4d10-8ff6-ffb1e6782d9f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>n_topic</th>\n",
       "      <th>coherence_score</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>0.525972</td>\n",
       "      <td>10:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>0.491855</td>\n",
       "      <td>13:46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8</td>\n",
       "      <td>0.483164</td>\n",
       "      <td>16:37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10</td>\n",
       "      <td>0.481007</td>\n",
       "      <td>26:21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>12</td>\n",
       "      <td>0.490952</td>\n",
       "      <td>36:22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14</td>\n",
       "      <td>0.477404</td>\n",
       "      <td>48:30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16</td>\n",
       "      <td>0.463993</td>\n",
       "      <td>1:03:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   n_topic  coherence_score     time\n",
       "0        4         0.525972    10:30\n",
       "1        6         0.491855    13:46\n",
       "2        8         0.483164    16:37\n",
       "3       10         0.481007    26:21\n",
       "4       12         0.490952    36:22\n",
       "5       14         0.477404    48:30\n",
       "6       16         0.463993  1:03:06"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_topics = [4, 6, 8, 10, 12, 14, 16]\n",
    "coherence_scores = [0.525972, 0.491855, 0.483164, 0.481007, 0.490952, 0.477404, 0.463993]\n",
    "time = [\"10:30\", \"13:46\", \"16:37\", \"26:21\", \"36:22\", \"48:30\", \"1:03:06\"]\n",
    "\n",
    "gensim_res = pd.DataFrame({\"n_topic\": n_topics, \"coherence_score\": coherence_scores, \"time\": time})\n",
    "gensim_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3b8e082-fcb2-41de-940a-7c1d0ab95c1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "69244afe-b4ba-4874-ba94-a8dd719f5cd6",
   "metadata": {
    "tags": []
   },
   "source": [
    "## LDA with K-Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ae4b989-d054-4de6-95d3-e6fc46344b7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bokeh \n",
    "#!pip install ktrain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0c49d1f0-8881-466d-9c66-5ffe9e17194d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bokeh Version: 2.4.3\n",
      "Ktrain Version: 0.37.0\n"
     ]
    }
   ],
   "source": [
    "import bokeh\n",
    "import ktrain\n",
    "print('Bokeh Version: ' + bokeh.__version__)\n",
    "print('Ktrain Version: ' + ktrain.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4225574d-d9ea-42da-aa42-0886128b4ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = df['main_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f5faeb04-2aee-4528-9d8b-9408bbd0764a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang: en\n",
      "preprocessing texts...\n",
      "fitting model...\n",
      "iteration: 1 of max_iter: 5\n",
      "iteration: 2 of max_iter: 5\n",
      "iteration: 3 of max_iter: 5\n",
      "iteration: 4 of max_iter: 5\n",
      "iteration: 5 of max_iter: 5\n",
      "done.\n",
      "CPU times: user 2h 10min 21s, sys: 4h 58min 1s, total: 7h 8min 23s\n",
      "Wall time: 34min 39s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tm = ktrain.text.get_topic_model(\n",
    "    texts=texts, \n",
    "    n_topics=20, \n",
    "    n_features=10000, \n",
    "    min_df=5, \n",
    "    max_df=0.5, \n",
    "    stop_words='english', \n",
    "    model_type='lda', \n",
    "    lda_max_iter=5, \n",
    "    verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7606c9f7-73c0-4a8b-9da0-5a3bbd31ed5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done.\n",
      "CPU times: user 20min 28s, sys: 43min 24s, total: 1h 3min 52s\n",
      "Wall time: 6min 25s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "tm.build(texts, threshold=0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "477f84a8-74e9-4fc3-b8d1-f2c4af66e13e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "topic:0 | count:18040 | solutions platform business cloud software learning company applications machine customers\n",
      "topic:15 | count:14281 | market report analysis global growth industry key research players forecast\n",
      "topic:5 | count:13395 | like human learning time make people model machine just used\n",
      "topic:7 | count:7731 | health healthcare medical care patients clinical drug research patient cancer\n",
      "topic:17 | count:7659 | customer experience content platform customers business marketing digital company conversational\n",
      "topic:11 | count:7603 | india news said world china global live indian government covid-19\n",
      "topic:10 | count:7553 | video content app news users opens music art like image\n",
      "topic:14 | count:6816 | google microsoft openai said search chatgpt company bing tech users\n",
      "topic:6 | count:6398 | security said use systems government people law privacy work rights\n",
      "topic:12 | count:5932 | said people says images musk like news company media years\n",
      "topic:9 | count:4879 | chatgpt text openai chatbot language said generative tool use writing\n",
      "topic:3 | count:4828 | company stock investment financial million shares investors year trading market\n",
      "topic:2 | count:4543 | market learning machine growth global forecast research service services report\n",
      "topic:4 | count:3207 | edge smart devices chip product products chips mobile nvidia camera\n",
      "topic:18 | count:2445 | science learning machine education students course skills starfilled university courses\n",
      "topic:13 | count:2219 | insurance statements company quotes forward-looking online information drivers und release\n",
      "topic:8 | count:1670 | market corporation ibm global growth report automotive vision intel systems\n",
      "topic:1 | count:1530 | news finance yahoo screener cookies cookie markets mail mutual website\n",
      "topic:16 | count:1381 | paid program best brandvoice forbes richest credit insurance cars cards\n",
      "topic:19 | count:1301 | crypto dollar traded learning machine btc trades blockchain decentralized investment\n"
     ]
    }
   ],
   "source": [
    "tm.print_topics(show_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f0c9e146-06f8-4949-b523-a62a15ca2e17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 130 ms, sys: 0 ns, total: 130 ms\n",
      "Wall time: 128 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "topic_doc = []\n",
    "\n",
    "for i in range(20):\n",
    "    topic_doc.append([text['text'] for text in tm.get_docs(topic_ids=[i], rank=True)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "abdeb8b8-28d4-426d-b1c2-ee896c307ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_topic(text):\n",
    "    \n",
    "    for idx, topic in enumerate(topic_doc):\n",
    "        if text in topic:\n",
    "            return str(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "9fe4daa5-97fb-47c1-9fe1-4aa31d3d0342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9be623bced6d4f43993050d774fe92e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "VBox(children=(HBox(children=(IntProgress(value=0, description='0.00%', max=8516), Label(value='0 / 8516'))), …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['ktrain_topic'] = df['main_text'].parallel_apply(assign_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d0ae975a-163d-4625-97d6-bae47d8752c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>date</th>\n",
       "      <th>title</th>\n",
       "      <th>text</th>\n",
       "      <th>main_text</th>\n",
       "      <th>relevant</th>\n",
       "      <th>Tokens</th>\n",
       "      <th>cleaned_tokens</th>\n",
       "      <th>ktrain_topic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>http://en.people.cn/n3/2021/0318/c90000-983012...</td>\n",
       "      <td>2021-03-18</td>\n",
       "      <td>Artificial intelligence improves parking effic...</td>\n",
       "      <td>\\n\\nArtificial intelligence improves parking e...</td>\n",
       "      <td>Photo taken on July 1, 2019, shows a sign for ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Photo, taken, on, July, 1, ,, 2019, ,, shows,...</td>\n",
       "      <td>[Photo, taken, July, show, sign, electronic, t...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>http://newsparliament.com/2020/02/27/children-...</td>\n",
       "      <td>2020-02-27</td>\n",
       "      <td>Children With Autism Saw Their Learning and So...</td>\n",
       "      <td>\\nChildren With Autism Saw Their Learning and ...</td>\n",
       "      <td>Children With Autism Saw Their Learning and So...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Children, With, Autism, Saw, Their, Learning,...</td>\n",
       "      <td>[Children, With, Autism, Saw, Their, Learning,...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>http://www.dataweek.co.za/12835r</td>\n",
       "      <td>2021-03-26</td>\n",
       "      <td>Forget ML, AI and Industry 4.0 – obsolescence ...</td>\n",
       "      <td>\\n\\nForget ML, AI and Industry 4.0 – obsolesce...</td>\n",
       "      <td>Forget ML, AI and Industry 4.0 – obsolescence ...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Forget, ML, ,, AI, and, Industry, 4.0, –, obs...</td>\n",
       "      <td>[Forget, ML, AI, Industry, obsolescence, focus...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>http://www.homeoffice.consumerelectronicsnet.c...</td>\n",
       "      <td>2021-03-10</td>\n",
       "      <td>Strategy Analytics: 71% of Smartphones Sold Gl...</td>\n",
       "      <td>\\n\\nStrategy Analytics: 71% of Smartphones Sol...</td>\n",
       "      <td>Strategy Analytics: 71% of Smartphones Sold Gl...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Strategy, Analytics, :, 71, %, of, Smartphone...</td>\n",
       "      <td>[Strategy, Analytics, Smartphones, Sold, Globa...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>http://www.itbusinessnet.com/2020/10/olympus-t...</td>\n",
       "      <td>2020-10-20</td>\n",
       "      <td>Olympus to Support Endoscopic AI Diagnosis Edu...</td>\n",
       "      <td>\\n\\nOlympus to Support Endoscopic AI Diagnosis...</td>\n",
       "      <td>Olympus to Support Endoscopic AI Diagnosis Edu...</td>\n",
       "      <td>1</td>\n",
       "      <td>[Olympus, to, Support, Endoscopic, AI, Diagnos...</td>\n",
       "      <td>[Olympus, Support, Endoscopic, AI, Diagnosis, ...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 url        date  \\\n",
       "0  http://en.people.cn/n3/2021/0318/c90000-983012...  2021-03-18   \n",
       "1  http://newsparliament.com/2020/02/27/children-...  2020-02-27   \n",
       "2                   http://www.dataweek.co.za/12835r  2021-03-26   \n",
       "3  http://www.homeoffice.consumerelectronicsnet.c...  2021-03-10   \n",
       "4  http://www.itbusinessnet.com/2020/10/olympus-t...  2020-10-20   \n",
       "\n",
       "                                               title  \\\n",
       "0  Artificial intelligence improves parking effic...   \n",
       "1  Children With Autism Saw Their Learning and So...   \n",
       "2  Forget ML, AI and Industry 4.0 – obsolescence ...   \n",
       "3  Strategy Analytics: 71% of Smartphones Sold Gl...   \n",
       "4  Olympus to Support Endoscopic AI Diagnosis Edu...   \n",
       "\n",
       "                                                text  \\\n",
       "0  \\n\\nArtificial intelligence improves parking e...   \n",
       "1  \\nChildren With Autism Saw Their Learning and ...   \n",
       "2  \\n\\nForget ML, AI and Industry 4.0 – obsolesce...   \n",
       "3  \\n\\nStrategy Analytics: 71% of Smartphones Sol...   \n",
       "4  \\n\\nOlympus to Support Endoscopic AI Diagnosis...   \n",
       "\n",
       "                                           main_text  relevant  \\\n",
       "0  Photo taken on July 1, 2019, shows a sign for ...         1   \n",
       "1  Children With Autism Saw Their Learning and So...         1   \n",
       "2  Forget ML, AI and Industry 4.0 – obsolescence ...         1   \n",
       "3  Strategy Analytics: 71% of Smartphones Sold Gl...         1   \n",
       "4  Olympus to Support Endoscopic AI Diagnosis Edu...         1   \n",
       "\n",
       "                                              Tokens  \\\n",
       "0  [Photo, taken, on, July, 1, ,, 2019, ,, shows,...   \n",
       "1  [Children, With, Autism, Saw, Their, Learning,...   \n",
       "2  [Forget, ML, ,, AI, and, Industry, 4.0, –, obs...   \n",
       "3  [Strategy, Analytics, :, 71, %, of, Smartphone...   \n",
       "4  [Olympus, to, Support, Endoscopic, AI, Diagnos...   \n",
       "\n",
       "                                      cleaned_tokens ktrain_topic  \n",
       "0  [Photo, taken, July, show, sign, electronic, t...            5  \n",
       "1  [Children, With, Autism, Saw, Their, Learning,...            5  \n",
       "2  [Forget, ML, AI, Industry, obsolescence, focus...            5  \n",
       "3  [Strategy, Analytics, Smartphones, Sold, Globa...            0  \n",
       "4  [Olympus, Support, Endoscopic, AI, Diagnosis, ...            7  "
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e20bf937-8175-48bc-8df2-5f3f64869b5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     18040\n",
       "15    14281\n",
       "5     13395\n",
       "7      7731\n",
       "17     7659\n",
       "11     7603\n",
       "10     7553\n",
       "14     6816\n",
       "6      6398\n",
       "12     5932\n",
       "9      4879\n",
       "3      4828\n",
       "2      4543\n",
       "4      3207\n",
       "18     2445\n",
       "13     2219\n",
       "8      1670\n",
       "1      1530\n",
       "16     1381\n",
       "19     1301\n",
       "Name: ktrain_topic, dtype: int64"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['ktrain_topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3e8346d0-9390-4f28-ba43-0150be5cdd10",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "table = pa.Table.from_pandas(df)\n",
    "pq.write_table(table, './data_topic.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d6b72cd4-fab8-46fc-b21c-7b32a6d165a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#doc_topics=tm.get_doctopics()\n",
    "#tm.visualize_documents(doc_topics=tm.get_doctopics())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bbc39b1c-fc07-45d4-9698-6714ae1c5378",
   "metadata": {},
   "source": [
    "## BERTopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "deb80b00-bb2e-420a-8736-8f15731793c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install bertopic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e4ba5dc5-b31a-4011-bd6d-6ec419b018a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-25 23:48:53.804977: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-25 23:48:55.189069: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-25 23:48:55.189279: W tensorflow/compiler/xla/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/cuda/lib:/usr/local/lib/x86_64-linux-gnu:/usr/local/nvidia/lib:/usr/local/nvidia/lib64:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2023-05-25 23:48:55.189297: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from bertopic import BERTopic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ebb29c8-ac17-4f71-a6da-47199466c280",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Cleaned_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6ffe6105-99e8-4465-a7f8-4654bdf4006f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4.86 s, sys: 331 ms, total: 5.19 s\n",
      "Wall time: 5.2 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "articles = df['cleaned_tokens'].tolist()\n",
    "text = [' '.join(tokens) for tokens in articles]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e0df846a-5919-4e7b-a98e-ef920d41151d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "CPU times: user 17h 53min 14s, sys: 1h 19min 55s, total: 19h 13min 10s\n",
      "Wall time: 2h 32min 32s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create an instance of BERTopic\n",
    "#topic_model = BERTopic(embedding_model = \"bert-base-nli-mean-tokens\",  min_topic_size = 150)\n",
    "topic_model = BERTopic(embedding_model = \"bert-base-nli-mean-tokens\",  min_topic_size = 50)\n",
    "# Fit the BERTopic model on your data\n",
    "topics, _ = topic_model.fit_transform(text)\n",
    "\n",
    "# Get the most frequent topics\n",
    "top_topics = topic_model.get_topic_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc5102b6-8de0-4754-948a-0b1016e69132",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic -1: ai, new, model, company, technology, the, data, said, like, use\n",
      "Topic 0: market, report, growth, analysis, global, forecast, artificial, key, size, intelligence\n",
      "Topic 1: patient, cancer, clinical, health, medical, disease, healthcare, care, protein, treatment\n",
      "Topic 2: market, analysis, report, growth, forecast, global, key, players, corporation, size\n",
      "Topic 3: china, chinese, baidu, beijing, ernie, alibaba, military, chip, government, us\n",
      "Topic 4: watch, india, live, says, to, from, telecast, after, updates, day\n",
      "Topic 5: stock, investor, trading, billion, year, company, investment, fool, million, quarter\n",
      "Topic 6: vehicle, car, road, traffic, driver, driving, safety, automotive, autonomous, fleet\n",
      "Topic 7: customer, solution, nvidia, platform, edge, enterprise, ddn, supermicro, performance, capability\n",
      "Topic 8: und, zu, auf, die, sie, im, bewerten, stoxx, nicht, al\n",
      "Topic 9: trends, nyse, forecast, reports, dagoretti, times, opportunities, size, growth, analysis\n",
      "Topic 10: student, education, science, school, course, programme, university, college, skill, fe\n",
      "Topic 11: drone, military, defense, aircraft, air, dod, force, army, pentagon, pilot\n",
      "Topic 12: eu, patent, regulation, law, inventor, european, system, rule, commission, act\n",
      "Topic 13: market, report, analysis, murphy, artificial, growth, global, intelligence, hockey, industry\n",
      "Topic 14: food, restaurant, recipe, grocery, chef, pizza, kitchen, order, ingredient, cooking\n",
      "Topic 15: healthcare, medical, medicine, market, imaging, report, artificial, intelligence, analysis, global\n",
      "Topic 16: starfilled, course, filled, certificate, helpful, starby, coursera, skillsskills, specialization, science\n",
      "Topic 17: ibm, corporation, intel, nyse, microsoft, dagoretti, times, google, players, sap\n",
      "Topic 18: paid, brandvoice, program, richest, forbes, best, cards, car, cars, insurance\n"
     ]
    }
   ],
   "source": [
    "# Print the top N topics\n",
    "N = 20\n",
    "\n",
    "for topic in top_topics.head(N)['Topic']:\n",
    "    topic_words = [word[0] for word in topic_model.get_topic(topic)]\n",
    "    print(f\"Topic {topic}: {', '.join(topic_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c4c45e90-87b7-4d66-a074-21d13e006c3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "topic_model.save('bertopic2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8de5ddce-9e2d-40b4-98aa-932c51dbae31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1_ai_new_model_company                      53124\n",
       "0_market_report_growth_analysis               7625\n",
       "1_patient_cancer_clinical_health              4522\n",
       "2_market_analysis_report_growth               2735\n",
       "3_china_chinese_baidu_beijing                 1517\n",
       "                                             ...  \n",
       "389_aeye_diagnosable_retinopathy_diabetic       51\n",
       "385_deepmotion_namco_bandai_forms               51\n",
       "384_kheiron_areas_stanford_oncology             51\n",
       "392_crypto_under_defi_brokersstock              50\n",
       "391_chief_north_america_canada                  50\n",
       "Name: Name, Length: 394, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = topic_model.get_document_info(text)\n",
    "res['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00456a87-9a3f-4861-a83c-aea69cbcc4a2",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "### Title "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6068b149-e7ab-40fe-a3a9-7956dfe73e19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9dbfbc83-d6c5-4739-ac05-7a45780d7f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "#nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "78879451-7c4c-43d0-b29a-f986ace0d4d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "aef2979f-a6d2-48f2-8fe5-64ba7ecfda4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "title_ls = df['title'].tolist()\n",
    "#convert to lowercase\n",
    "title_ls = [title.lower() for title in title_ls]\n",
    "#remove stopwords\n",
    "cleaned_title = []\n",
    "for title in title_ls: \n",
    "    tokens = title.split(' ')\n",
    "    cleaned_tokens = []\n",
    "    for token in tokens:\n",
    "        if token not in stop_words:\n",
    "            cleaned_tokens.append(token)\n",
    "            \n",
    "    cleaned_title.append(' '.join(cleaned_tokens))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "709bfd5e-7ae7-45ba-95a4-6ca6779df980",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "CPU times: user 5h 26min 22s, sys: 10min 45s, total: 5h 37min 8s\n",
      "Wall time: 42min 23s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Create an instance of BERTopic\n",
    "title_topic_model = BERTopic(embedding_model = \"bert-base-nli-mean-tokens\",  min_topic_size = 150)\n",
    "\n",
    "# Fit the BERTopic model on your data\n",
    "title_topics, _ = title_topic_model.fit_transform(cleaned_title)\n",
    "\n",
    "# Get the most frequent topics\n",
    "title_top_topics = title_topic_model.get_topic_freq()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "de2ed55c-b516-4897-81bb-f87ccdfde74a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic -1: ai, new, chatgpt, data, platform, com, news, intelligence, launches, technology\n",
      "Topic 0: market, growth, analysis, 2020, global, forecast, ibm, 2026, players, corporation\n",
      "Topic 1: million, billion, raises, american, banking, usd, cagr, reach, news, 10\n",
      "Topic 2: chatgpt, breaking, news, ai, breakinglatest, google, musk, latest, says, elon\n",
      "Topic 3: cancer, health, healthcare, medical, breast, drug, patients, news, care, predict\n",
      "Topic 4: google, bard, search, chatbot, rival, exbulletin, chatgpt, engineer, sentient, cloud\n",
      "Topic 5: healthcare, medical, market, medicine, growth, corporation, 2020, drug, global, analysis\n",
      "Topic 6: china, chinese, us, morning, chatgpt, baidu, south, frenzy, alibaba, post\n",
      "Topic 7: automotive, cars, ford, driving, car, argo, market, self, corporation, autonomous\n",
      "Topic 8: artificial, intelligence, future, new, human, art, need, com, news, digital\n",
      "Topic 9: microsoft, bing, search, azure, chatgpt, openai, bakes, engine, word, excel\n",
      "Topic 10: department, defense, military, house, homeland, white, force, pentagon, patent, federal\n",
      "Topic 11: machine, learning, coursera, learner, feedback, reviews, course, data, aws, models\n",
      "Topic 12: year, week, nasdaq, second, day, month, consecutive, next, conference, three\n",
      "Topic 13: better, smarter, faster, make, improve, easier, safer, ai, customer, help\n",
      "Topic 14: students, iit, school, education, science, data, online, madras, degree, indian\n",
      "Topic 15: financial, stock, guardforce, gfai, limited, co, soun, ses, soundhound, finance\n",
      "Topic 16: agriculture, agribotix, deere, granular, awhere, agricultural, climate, prospera, market, cainthus\n",
      "Topic 17: best, award, wins, fastest, supercomputer, laivly, world, top, excellence, awards\n",
      "Topic 18: food, beverage, beverages, herald, intelligentx, brewing, tomra, greefa, flavor, aboard\n"
     ]
    }
   ],
   "source": [
    "# Print the top N topics\n",
    "N = 20\n",
    "\n",
    "for topic in title_top_topics.head(N)['Topic']:\n",
    "    topic_words = [word[0] for word in title_topic_model.get_topic(topic)]\n",
    "    print(f\"Topic {topic}: {', '.join(topic_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "97fd2d10-3ece-421b-963a-316ea295bffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "title_topic_model.save('title_bertopic')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b1a08ec7-a8a0-4cf8-8c6c-eedcfc85faaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1_ai_new_chatgpt_data                           57733\n",
       "0_market_growth_analysis_2020                    12755\n",
       "1_million_billion_raises_american                10426\n",
       "2_chatgpt_breaking_news_ai                        7706\n",
       "3_cancer_health_healthcare_medical                3846\n",
       "                                                 ...  \n",
       "74_pen_channels_history_union                      164\n",
       "75_ensure_safe_must_biden                          154\n",
       "77_rokit_bioprinting_osteoarthritis_radiology      153\n",
       "76_coursera_data_science_scientist                 153\n",
       "78_israel_israeli_jerusalem_weizmann               150\n",
       "Name: Name, Length: 80, dtype: int64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = title_topic_model.get_document_info(cleaned_title)\n",
    "res['Name'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2fe599-02a3-4b16-8311-079a0cbe402b",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Identify topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32332145-c81b-442c-8724-068a980c3c65",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "87f7b98c-fb08-47b7-9e10-a972cc1b23c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "saved_model = BERTopic.load('bertopic2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "f0e13846-1619-42b2-b8df-938db465fc0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic -1: ai, new, model, company, technology, the, data, said, like, use\n",
      "Topic 0: market, report, growth, analysis, global, forecast, artificial, key, size, intelligence\n",
      "Topic 1: patient, cancer, clinical, health, medical, disease, healthcare, care, protein, treatment\n",
      "Topic 2: market, analysis, report, growth, forecast, global, key, players, corporation, size\n",
      "Topic 3: china, chinese, baidu, beijing, ernie, alibaba, military, chip, government, us\n",
      "Topic 4: watch, india, live, says, to, from, telecast, after, updates, day\n",
      "Topic 5: stock, investor, trading, billion, year, company, investment, fool, million, quarter\n",
      "Topic 6: vehicle, car, road, traffic, driver, driving, safety, automotive, autonomous, fleet\n",
      "Topic 7: customer, solution, nvidia, platform, edge, enterprise, ddn, supermicro, performance, capability\n",
      "Topic 8: und, zu, auf, die, sie, im, bewerten, stoxx, nicht, al\n",
      "Topic 9: trends, nyse, forecast, reports, dagoretti, times, opportunities, size, growth, analysis\n",
      "Topic 10: student, education, science, school, course, programme, university, college, skill, fe\n",
      "Topic 11: drone, military, defense, aircraft, air, dod, force, army, pentagon, pilot\n",
      "Topic 12: eu, patent, regulation, law, inventor, european, system, rule, commission, act\n",
      "Topic 13: market, report, analysis, murphy, artificial, growth, global, intelligence, hockey, industry\n",
      "Topic 14: food, restaurant, recipe, grocery, chef, pizza, kitchen, order, ingredient, cooking\n",
      "Topic 15: healthcare, medical, medicine, market, imaging, report, artificial, intelligence, analysis, global\n",
      "Topic 16: starfilled, course, filled, certificate, helpful, starby, coursera, skillsskills, specialization, science\n",
      "Topic 17: ibm, corporation, intel, nyse, microsoft, dagoretti, times, google, players, sap\n",
      "Topic 18: paid, brandvoice, program, richest, forbes, best, cards, car, cars, insurance\n",
      "Topic 19: funding, round, capital, ventures, company, customer, platform, enterprise, quantexa, team\n",
      "Topic 20: weather, inappropriate, post, comment, lehigh, berks, poconos, cloudy, allentown, shower\n",
      "Topic 21: data, organization, business, ml, process, need, skill, job, customer, ai\n",
      "Topic 22: student, school, teacher, chatgpt, essay, educator, assignment, writing, cheating, district\n",
      "Topic 23: upthis, recaptcha, newslettersign, notice, terms, protected, linkscontact, my, adadvertisementhide, ipso\n",
      "Topic 24: india, discourse, partnership, submit, advertisement, news, minister, urban, government, roundup\n",
      "Topic 25: music, song, artist, lyric, sound, musician, drake, musical, averill, spotify\n",
      "Topic 26: bing, bard, google, search, microsoft, engine, tab, chatgpt, chatbot, openai\n",
      "Topic 27: gebru, google, fired, mitchell, employee, lemoine, timnit, firing, lamda, bengio\n",
      "Topic 28: space, earth, galaxy, nasa, planet, telescope, satellite, crater, moon, hole\n",
      "Topic 29: finance, yahoo, screener, screeners, alexandra, markets, andy, mutual, highest, screenerfutures\n",
      "Topic 30: automotive, automobile, market, trucks, artificial, intelligence, report, analysis, corporation, global\n",
      "Topic 31: screener, yahoo, finance, futures, screeners, events, stocks, mail, etf, crypto\n",
      "Topic 32: canada, canadian, hashtag, clearview, privacy, canadians, commissioner, trending, therrien, rcmp\n",
      "Topic 33: crypto, under, defi, stocksbest, brokersstock, nfts, cryptocurrency, alternative, bankrate, advertisers\n",
      "Topic 34: mail, yahoo, originals, news, skullduggery, oakland, politics, sign, conspiracyland, us\n",
      "Topic 35: to, adani, of, tax, rs, bank, et, times, prime, india\n",
      "Topic 36: chief, north, america, business, technology, blackberry, ai, unveils, wii, apple\n",
      "Topic 37: sun, youmore, newspapers, likerecommended, footballall, contentsign, sunjump, sunservicessign, settingscontact, topicsartificial\n",
      "Topic 38: canada, canadian, statement, toronto, release, company, tsx, result, exploration, information\n",
      "CPU times: user 2.69 ms, sys: 4.02 ms, total: 6.71 ms\n",
      "Wall time: 5.06 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Get the most frequent topics\n",
    "new_top_topics = saved_model.get_topic_freq()\n",
    "# Print the top N topics\n",
    "N = 40\n",
    "\n",
    "for topic in new_top_topics.head(N)['Topic']:\n",
    "    topic_words = [word[0] for word in saved_model.get_topic(topic)]\n",
    "    print(f\"Topic {topic}: {', '.join(topic_words)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "6ad7af6b-5239-48b2-b283-9971b9ced01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#assign industry tag to each topic\n",
    "industry_name = ['Others']\n",
    "\n",
    "for i in range(len(new_top_topics['Topic'])-1):\n",
    "    \n",
    "    sample = [word[0] for word in saved_model.get_topic(i)]\n",
    "    \n",
    "    if re.search(r\"crypto(currency)?|blockchain|finance|btc|bank(ing)?|loan|fintech\", ' '.join(sample), flags=re.I): industry_name.append('Finance')\n",
    "    elif re.search(r\"patient|health(care)?|cancer|clinical|drug|medicine|genomics\", ' '.join(sample), flags=re.I): industry_name.append('Healthcare&Biotech')\n",
    "    elif re.search(r\"student|classroom|education|coursera|essay|school|academic\", ' '.join(sample), flags=re.I): industry_name.append('Education')\n",
    "    elif re.search(r\"music|song|photoshop|painting|artist|photography|film\", ' '.join(sample), flags=re.I): industry_name.append('Media Creation')\n",
    "    elif re.search(r\"automative|vehicle|tesla|elon|car|energy|automobile\", ' '.join(sample), flags=re.I): industry_name.append('Automotive')\n",
    "    elif re.search(r\"telecom|telecast|5g|IoT|mobile|satellite|fiber optics\", ' '.join(sample), flags=re.I): industry_name.append('Telecommunication')\n",
    "    elif re.search(r\"agriculture|farm(ing)?|agribotix|farmer|livestock|pest|soil\", ' '.join(sample), flags=re.I): industry_name.append('Agriculture')\n",
    "    elif re.search(r\"writer|publication(s)?|book(s)?|publishing|magazine|author|newspapers\", ' '.join(sample), flags=re.I): industry_name.append('Publishing')\n",
    "    elif re.search(r\"google|ibm|microsoft|facebook|chip(s)|meta|chatgpt\", ' '.join(sample), flags=re.I): industry_name.append('Technology')\n",
    "    elif re.search(r\"military|defense|aircraft|space|cybersecurity|drone|army\", ' '.join(sample), flags=re.I): industry_name.append('Military & Defense')\n",
    "    else: industry_name.append('Others')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "6c3494ad-6fbd-4077-92c7-71b8a2e8b849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "      <th>industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1_ai_new_model_company</td>\n",
       "      <td>53124</td>\n",
       "      <td>53124</td>\n",
       "      <td>53124</td>\n",
       "      <td>53124</td>\n",
       "      <td>53124</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0_market_report_growth_analysis</td>\n",
       "      <td>7625</td>\n",
       "      <td>7625</td>\n",
       "      <td>7625</td>\n",
       "      <td>7625</td>\n",
       "      <td>7625</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_patient_cancer_clinical_health</td>\n",
       "      <td>4522</td>\n",
       "      <td>4522</td>\n",
       "      <td>4522</td>\n",
       "      <td>4522</td>\n",
       "      <td>4522</td>\n",
       "      <td>Healthcare&amp;Biotech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2_market_analysis_report_growth</td>\n",
       "      <td>2735</td>\n",
       "      <td>2735</td>\n",
       "      <td>2735</td>\n",
       "      <td>2735</td>\n",
       "      <td>2735</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3_china_chinese_baidu_beijing</td>\n",
       "      <td>1517</td>\n",
       "      <td>1517</td>\n",
       "      <td>1517</td>\n",
       "      <td>1517</td>\n",
       "      <td>1517</td>\n",
       "      <td>Military &amp; Defense</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                               Name  Document  Topic  Top_n_words  \\\n",
       "0           -1_ai_new_model_company     53124  53124        53124   \n",
       "1   0_market_report_growth_analysis      7625   7625         7625   \n",
       "2  1_patient_cancer_clinical_health      4522   4522         4522   \n",
       "3   2_market_analysis_report_growth      2735   2735         2735   \n",
       "4     3_china_chinese_baidu_beijing      1517   1517         1517   \n",
       "\n",
       "   Probability  Representative_document            industry  \n",
       "0        53124                    53124              Others  \n",
       "1         7625                     7625              Others  \n",
       "2         4522                     4522  Healthcare&Biotech  \n",
       "3         2735                     2735              Others  \n",
       "4         1517                     1517  Military & Defense  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic_cnt = saved_model.get_document_info(text).groupby('Name').count().sort_values(by = 'Document', ascending = False).reset_index()\n",
    "topic_cnt['industry'] = industry_name\n",
    "topic_cnt.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "aa4c35e6-d667-4179-bad1-f529dee2aad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# map the industry label to the dataframe\n",
    "industry_label = {'Key': topic_cnt['Name'].tolist(),\n",
    "                  'Value': topic_cnt['industry'].tolist()}\n",
    "\n",
    "industry_label_df = pd.DataFrame(industry_label)\n",
    "\n",
    "result_dict = industry_label_df.set_index('Key')['Value'].to_dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "295ee2cb-cf87-4f8c-945f-34bca3251cff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photo taken July show sign electronic toll col...</td>\n",
       "      <td>6</td>\n",
       "      <td>6_vehicle_car_road_traffic</td>\n",
       "      <td>vehicle - car - road - traffic - driver - driv...</td>\n",
       "      <td>0.618081</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Children With Autism Saw Their Learning Social...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_ai_new_model_company</td>\n",
       "      <td>ai - new - model - company - technology - the ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forget ML AI Industry obsolescence focus Febru...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_ai_new_model_company</td>\n",
       "      <td>ai - new - model - company - technology - the ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Strategy Analytics Smartphones Sold Globally A...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_ai_new_model_company</td>\n",
       "      <td>ai - new - model - company - technology - the ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Olympus Support Endoscopic AI Diagnosis Educat...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_ai_new_model_company</td>\n",
       "      <td>ai - new - model - company - technology - the ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Topic  \\\n",
       "0  Photo taken July show sign electronic toll col...      6   \n",
       "1  Children With Autism Saw Their Learning Social...     -1   \n",
       "2  Forget ML AI Industry obsolescence focus Febru...     -1   \n",
       "3  Strategy Analytics Smartphones Sold Globally A...     -1   \n",
       "4  Olympus Support Endoscopic AI Diagnosis Educat...     -1   \n",
       "\n",
       "                         Name  \\\n",
       "0  6_vehicle_car_road_traffic   \n",
       "1     -1_ai_new_model_company   \n",
       "2     -1_ai_new_model_company   \n",
       "3     -1_ai_new_model_company   \n",
       "4     -1_ai_new_model_company   \n",
       "\n",
       "                                         Top_n_words  Probability  \\\n",
       "0  vehicle - car - road - traffic - driver - driv...     0.618081   \n",
       "1  ai - new - model - company - technology - the ...     0.000000   \n",
       "2  ai - new - model - company - technology - the ...     0.000000   \n",
       "3  ai - new - model - company - technology - the ...     0.000000   \n",
       "4  ai - new - model - company - technology - the ...     0.000000   \n",
       "\n",
       "   Representative_document  \n",
       "0                    False  \n",
       "1                    False  \n",
       "2                    False  \n",
       "3                    False  \n",
       "4                    False  "
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_info = saved_model.get_document_info(text)\n",
    "doc_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e72dc515-e061-4f34-adaf-aa5e411bbffc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 26.8 ms, sys: 3.8 ms, total: 30.6 ms\n",
      "Wall time: 28.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "doc_info['Industry'] = doc_info['Name'].apply(lambda x: result_dict[x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "5eccf22b-c027-401d-b8db-af954c56aade",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Photo taken July show sign electronic toll col...</td>\n",
       "      <td>6</td>\n",
       "      <td>6_vehicle_car_road_traffic</td>\n",
       "      <td>vehicle - car - road - traffic - driver - driv...</td>\n",
       "      <td>0.618081</td>\n",
       "      <td>False</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Children With Autism Saw Their Learning Social...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_ai_new_model_company</td>\n",
       "      <td>ai - new - model - company - technology - the ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Forget ML AI Industry obsolescence focus Febru...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_ai_new_model_company</td>\n",
       "      <td>ai - new - model - company - technology - the ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Strategy Analytics Smartphones Sold Globally A...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_ai_new_model_company</td>\n",
       "      <td>ai - new - model - company - technology - the ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Olympus Support Endoscopic AI Diagnosis Educat...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1_ai_new_model_company</td>\n",
       "      <td>ai - new - model - company - technology - the ...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>False</td>\n",
       "      <td>Others</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Document  Topic  \\\n",
       "0  Photo taken July show sign electronic toll col...      6   \n",
       "1  Children With Autism Saw Their Learning Social...     -1   \n",
       "2  Forget ML AI Industry obsolescence focus Febru...     -1   \n",
       "3  Strategy Analytics Smartphones Sold Globally A...     -1   \n",
       "4  Olympus Support Endoscopic AI Diagnosis Educat...     -1   \n",
       "\n",
       "                         Name  \\\n",
       "0  6_vehicle_car_road_traffic   \n",
       "1     -1_ai_new_model_company   \n",
       "2     -1_ai_new_model_company   \n",
       "3     -1_ai_new_model_company   \n",
       "4     -1_ai_new_model_company   \n",
       "\n",
       "                                         Top_n_words  Probability  \\\n",
       "0  vehicle - car - road - traffic - driver - driv...     0.618081   \n",
       "1  ai - new - model - company - technology - the ...     0.000000   \n",
       "2  ai - new - model - company - technology - the ...     0.000000   \n",
       "3  ai - new - model - company - technology - the ...     0.000000   \n",
       "4  ai - new - model - company - technology - the ...     0.000000   \n",
       "\n",
       "   Representative_document    Industry  \n",
       "0                    False  Automotive  \n",
       "1                    False      Others  \n",
       "2                    False      Others  \n",
       "3                    False      Others  \n",
       "4                    False      Others  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_info.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "d9a8cdf5-7b72-4000-8ce5-7ea9bf2fd383",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Document</th>\n",
       "      <th>Topic</th>\n",
       "      <th>Name</th>\n",
       "      <th>Top_n_words</th>\n",
       "      <th>Probability</th>\n",
       "      <th>Representative_document</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Industry</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Others</th>\n",
       "      <td>96240</td>\n",
       "      <td>96240</td>\n",
       "      <td>96240</td>\n",
       "      <td>96240</td>\n",
       "      <td>96240</td>\n",
       "      <td>96240</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Healthcare&amp;Biotech</th>\n",
       "      <td>7432</td>\n",
       "      <td>7432</td>\n",
       "      <td>7432</td>\n",
       "      <td>7432</td>\n",
       "      <td>7432</td>\n",
       "      <td>7432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Automotive</th>\n",
       "      <td>4758</td>\n",
       "      <td>4758</td>\n",
       "      <td>4758</td>\n",
       "      <td>4758</td>\n",
       "      <td>4758</td>\n",
       "      <td>4758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Finance</th>\n",
       "      <td>4179</td>\n",
       "      <td>4179</td>\n",
       "      <td>4179</td>\n",
       "      <td>4179</td>\n",
       "      <td>4179</td>\n",
       "      <td>4179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Technology</th>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "      <td>3191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Military &amp; Defense</th>\n",
       "      <td>3124</td>\n",
       "      <td>3124</td>\n",
       "      <td>3124</td>\n",
       "      <td>3124</td>\n",
       "      <td>3124</td>\n",
       "      <td>3124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Telecommunication</th>\n",
       "      <td>2474</td>\n",
       "      <td>2474</td>\n",
       "      <td>2474</td>\n",
       "      <td>2474</td>\n",
       "      <td>2474</td>\n",
       "      <td>2474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Publishing</th>\n",
       "      <td>2324</td>\n",
       "      <td>2324</td>\n",
       "      <td>2324</td>\n",
       "      <td>2324</td>\n",
       "      <td>2324</td>\n",
       "      <td>2324</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Education</th>\n",
       "      <td>2300</td>\n",
       "      <td>2300</td>\n",
       "      <td>2300</td>\n",
       "      <td>2300</td>\n",
       "      <td>2300</td>\n",
       "      <td>2300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Media Creation</th>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "      <td>1070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Agriculture</th>\n",
       "      <td>647</td>\n",
       "      <td>647</td>\n",
       "      <td>647</td>\n",
       "      <td>647</td>\n",
       "      <td>647</td>\n",
       "      <td>647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Document  Topic   Name  Top_n_words  Probability  \\\n",
       "Industry                                                               \n",
       "Others                 96240  96240  96240        96240        96240   \n",
       "Healthcare&Biotech      7432   7432   7432         7432         7432   \n",
       "Automotive              4758   4758   4758         4758         4758   \n",
       "Finance                 4179   4179   4179         4179         4179   \n",
       "Technology              3191   3191   3191         3191         3191   \n",
       "Military & Defense      3124   3124   3124         3124         3124   \n",
       "Telecommunication       2474   2474   2474         2474         2474   \n",
       "Publishing              2324   2324   2324         2324         2324   \n",
       "Education               2300   2300   2300         2300         2300   \n",
       "Media Creation          1070   1070   1070         1070         1070   \n",
       "Agriculture              647    647    647          647          647   \n",
       "\n",
       "                    Representative_document  \n",
       "Industry                                     \n",
       "Others                                96240  \n",
       "Healthcare&Biotech                     7432  \n",
       "Automotive                             4758  \n",
       "Finance                                4179  \n",
       "Technology                             3191  \n",
       "Military & Defense                     3124  \n",
       "Telecommunication                      2474  \n",
       "Publishing                             2324  \n",
       "Education                              2300  \n",
       "Media Creation                         1070  \n",
       "Agriculture                             647  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc_info.groupby('Industry').count().sort_values(by = 'Document', ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6f93d98f-ae02-42e7-b597-d04090448634",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_info.to_csv('industry_info.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5917966-06cf-4202-9a3c-b5ca1a812767",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow 2 (Local)",
   "language": "python",
   "name": "local-tf2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
